{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`py_grama`\n",
    "\n",
    "---\n",
    "\n",
    "A demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import grama as gr\n",
    "from grama.models import make_cantilever_beam\n",
    "md_beam = make_cantilever_beam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Models have both *functions* and *distributions*\n",
    "md_beam.printpretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The model has a function + distribution;\n",
    "# Monte Carlo is now a one-liner\n",
    "df_mc = md_beam >> gr.ev_monte_carlo(n=100, df_det=\"nom\")\n",
    "\n",
    "df_mc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The resulting data have model context for plotting\n",
    "df_mc >> gr.pt_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities for sensitivity analysis\n",
    "md_beam >> \\\n",
    "    gr.ev_hybrid(n=500, df_det=\"nom\") >> \\\n",
    "    gr.tf_sobol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical exploration\n",
    "md_beam >> \\\n",
    "    gr.ev_sinews(df_det=\"nom\", skip=True) >> \\\n",
    "    gr.pt_auto()\n",
    "# rm `skip` for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Models are built in stages\n",
    "md_test = gr.Model(\"My model\") >> \\\n",
    "    gr.cp_function(\n",
    "        fun=lambda x: x[0] + x[1],\n",
    "        var=2,\n",
    "        out=1\n",
    "    ) >> \\\n",
    "    gr.cp_bounds(\n",
    "        x0=(0, 1)\n",
    "    ) >> \\\n",
    "    gr.cp_marginals(\n",
    "        x1={\"dist\": \"uniform\", \"loc\": 0, \"scale\": 1}\n",
    "    )\n",
    "md_test.printpretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cannot perform MC without an explicit dependence structure!\n",
    "# md_test >> gr.ev_monte_carlo(df_det=\"nom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can update a model; this allows us to\n",
    "# build up in stages\n",
    "md_test = \\\n",
    "    md_test >> \\\n",
    "    gr.cp_copula_independence()\n",
    "md_test.printpretty()\n",
    "md_test >> gr.ev_monte_carlo(df_det=\"nom\", seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can fit distributions from data...\n",
    "from grama.data import df_stang\n",
    "md_stang = gr.Model(\"E, mu distribution\") >> \\\n",
    "    gr.cp_marginals(\n",
    "        E=gr.marg_named(df_stang.E, \"norm\"),\n",
    "        mu=gr.marg_named(df_stang.mu, \"beta\")\n",
    "    ) >> \\\n",
    "    gr.cp_copula_gaussian(df_data=df_stang)\n",
    "md_stang.printpretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# and we can simulate from those fits\n",
    "df_stang_synthetic = \\\n",
    "    md_stang >> \\\n",
    "    gr.ev_monte_carlo(n=1e3, df_det=\"nom\", skip=True)\n",
    "df_stang_synthetic >> gr.pt_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some UQ knowledge is built into the tools\n",
    "# md_stang >> gr.ev_hybrid(n=500, df_det=\"nom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate / Metamodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Can build metamodels on data;\n",
    "# fit a gaussian process\n",
    "from grama.fit import fit_gp\n",
    "\n",
    "md_beam_meta = \\\n",
    "    fit_gp(\n",
    "        df_mc,\n",
    "        md=md_beam\n",
    "    )\n",
    "# Metamodel inherits model distribution\n",
    "md_beam_meta.printpretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Perform qualitative checks on a learned model\n",
    "md_beam_meta >> \\\n",
    "    gr.ev_sinews(df_det=\"nom\") >> \\\n",
    "    gr.pt_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fit_gp is a wrapper; we can use a scikit-learn kernel\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as Con\n",
    "kernel = Con(1, (1e-3, 1e+3)) * RBF([1] * 6, (1e-8, 1e+8))\n",
    "\n",
    "# Layered options with sensible defaults\n",
    "md_beam_custom = \\\n",
    "    fit_gp(\n",
    "        df_mc,\n",
    "        md=md_beam,\n",
    "        kernel=kernel\n",
    "    )\n",
    "md_beam_custom.printpretty()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
